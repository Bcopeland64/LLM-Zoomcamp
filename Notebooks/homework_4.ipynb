{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/04-monitoring/data/results-gpt4o-mini.csv?raw=1'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.iloc[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_orig</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You can sign up for the course by visiting the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Where can I sign up for the course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You can sign up using the link provided in the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Can you provide a link to sign up?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes, there is an FAQ for the Machine Learning ...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Is there an FAQ for this Machine Learning course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The context does not provide any specific info...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Does this course have a GitHub repository for ...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To structure your questions and answers for th...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>How can I structure my questions and answers f...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          answer_llm  \\\n",
       "0  You can sign up for the course by visiting the...   \n",
       "1  You can sign up using the link provided in the...   \n",
       "2  Yes, there is an FAQ for the Machine Learning ...   \n",
       "3  The context does not provide any specific info...   \n",
       "4  To structure your questions and answers for th...   \n",
       "\n",
       "                                         answer_orig  document  \\\n",
       "0  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "1  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "2  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "3  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "4  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "\n",
       "                                            question  \\\n",
       "0                Where can I sign up for the course?   \n",
       "1                 Can you provide a link to sign up?   \n",
       "2  Is there an FAQ for this Machine Learning course?   \n",
       "3  Does this course have a GitHub repository for ...   \n",
       "4  How can I structure my questions and answers f...   \n",
       "\n",
       "                      course  \n",
       "0  machine-learning-zoomcamp  \n",
       "1  machine-learning-zoomcamp  \n",
       "2  machine-learning-zoomcamp  \n",
       "3  machine-learning-zoomcamp  \n",
       "4  machine-learning-zoomcamp  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f077dea35bf4334a6fe33576e3458ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "499f1876cfb94ad39113fd2692046227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/212 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 3.0.0.dev0, however, your version is 2.7.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c44931002efc4711b0ad9882e5fc24e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.71k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caddaf4aa17a41f1b84fc75bac317819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brandon/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc656a5ef3a4c38b4caff8e3dab9d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f70d92edd6be4004b420c86ef5d99d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4611a04734c943c7a4c61dd11628393e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e883cf4ac454a48bee9ab6e0db2590d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c0dd8479b674fe2b19a89331f8d2b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dbd65033a6245018e80521e0e578b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a3164e321445699a42bd32477484bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first value of the resulting vector is: -0.4224465489387512\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the specified model\n",
    "model_name = 'multi-qa-mpnet-base-dot-v1'\n",
    "embedding_model = SentenceTransformer(model_name)\n",
    "\n",
    "# Assuming you have a DataFrame 'df' with a column 'answer_llm'\n",
    "answer_llm = df.iloc[0].answer_llm\n",
    "\n",
    "# Create the embeddings\n",
    "embeddings = embedding_model.encode(answer_llm)\n",
    "\n",
    "# Check the first value of the resulting vector\n",
    "first_value = embeddings[0]\n",
    "\n",
    "print(f\"The first value of the resulting vector is: {first_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 3.0.0.dev0, however, your version is 2.7.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 75th percentile of the scores is: 31.67430877685547\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the model\n",
    "model_name = 'multi-qa-mpnet-base-dot-v1'\n",
    "embedding_model = SentenceTransformer(model_name)\n",
    "\n",
    "# Initialize an empty list to store the scores\n",
    "evaluations = []\n",
    "\n",
    "# Iterate through each row in the dataframe\n",
    "for _, row in df.iterrows():\n",
    "    # Create embeddings for both answers\n",
    "    embedding1 = embedding_model.encode(row['answer_llm'])\n",
    "    embedding2 = embedding_model.encode(row['answer_orig'])\n",
    "    \n",
    "    # Compute dot product\n",
    "    score = np.dot(embedding1, embedding2)\n",
    "    \n",
    "    # Append the score to the evaluations list\n",
    "    evaluations.append(score)\n",
    "\n",
    "# Calculate the 75th percentile\n",
    "percentile_75 = np.percentile(evaluations, 75)\n",
    "\n",
    "print(f\"The 75th percentile of the scores is: {percentile_75}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 3.0.0.dev0, however, your version is 2.7.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 75th percentile of the cosine similarity scores is: 0.8362348973751068\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the model\n",
    "model_name = 'multi-qa-mpnet-base-dot-v1'\n",
    "embedding_model = SentenceTransformer(model_name)\n",
    "\n",
    "# Initialize an empty list to store the scores\n",
    "evaluations = []\n",
    "\n",
    "# Function to normalize a vector\n",
    "def normalize(v):\n",
    "    norm = np.sqrt((v * v).sum())\n",
    "    return v / norm\n",
    "\n",
    "# Iterate through each row in the dataframe\n",
    "for _, row in df.iterrows():\n",
    "    # Create embeddings for both answers\n",
    "    embedding1 = embedding_model.encode(row['answer_llm'])\n",
    "    embedding2 = embedding_model.encode(row['answer_orig'])\n",
    "    \n",
    "    # Normalize the embeddings\n",
    "    embedding1_norm = normalize(embedding1)\n",
    "    embedding2_norm = normalize(embedding2)\n",
    "    \n",
    "    # Compute cosine similarity (dot product of normalized vectors)\n",
    "    score = np.dot(embedding1_norm, embedding2_norm)\n",
    "    \n",
    "    # Append the score to the evaluations list\n",
    "    evaluations.append(score)\n",
    "\n",
    "# Calculate the 75th percentile\n",
    "percentile_75 = np.percentile(evaluations, 75)\n",
    "\n",
    "print(f\"The 75th percentile of the cosine similarity scores is: {percentile_75}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install rouge -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1 score for ROUGE-1 is: 0.45454544954545456\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "# Initialize the Rouge scorer\n",
    "rouge_scorer = Rouge()\n",
    "\n",
    "# Get the row at index 10 (document ID 5170565b)\n",
    "r = df.iloc[10]\n",
    "\n",
    "# Compute ROUGE scores\n",
    "scores = rouge_scorer.get_scores(r['answer_llm'], r['answer_orig'])[0]\n",
    "\n",
    "# Extract the F1 score for ROUGE-1\n",
    "rouge_1_f1 = scores['rouge-1']['f']\n",
    "\n",
    "print(f\"The F1 score for ROUGE-1 is: {rouge_1_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1 F1: 0.45454544954545456\n",
      "ROUGE-2 F1: 0.21621621121621637\n",
      "ROUGE-L F1: 0.393939388939394\n",
      "The average F1 score across ROUGE-1, ROUGE-2, and ROUGE-L is: 0.35490034990035496\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "# Initialize the Rouge scorer\n",
    "rouge_scorer = Rouge()\n",
    "\n",
    "# Get the row at index 10 (document ID 5170565b)\n",
    "r = df.iloc[10]\n",
    "\n",
    "# Compute ROUGE scores\n",
    "scores = rouge_scorer.get_scores(r['answer_llm'], r['answer_orig'])[0]\n",
    "\n",
    "# Extract F1 scores for ROUGE-1, ROUGE-2, and ROUGE-L\n",
    "rouge_1_f1 = scores['rouge-1']['f']\n",
    "rouge_2_f1 = scores['rouge-2']['f']\n",
    "rouge_l_f1 = scores['rouge-l']['f']\n",
    "\n",
    "# Calculate the average F1 score\n",
    "average_f1 = (rouge_1_f1 + rouge_2_f1 + rouge_l_f1) / 3\n",
    "\n",
    "print(f\"ROUGE-1 F1: {rouge_1_f1}\")\n",
    "print(f\"ROUGE-2 F1: {rouge_2_f1}\")\n",
    "print(f\"ROUGE-L F1: {rouge_l_f1}\")\n",
    "print(f\"The average F1 score across ROUGE-1, ROUGE-2, and ROUGE-L is: {average_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average ROUGE-2 score across all records is: 0.20696501983423318\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rouge import Rouge\n",
    "\n",
    "# Initialize the Rouge scorer\n",
    "rouge_scorer = Rouge()\n",
    "\n",
    "# Function to compute ROUGE scores for a single row\n",
    "def compute_rouge_scores(row):\n",
    "    scores = rouge_scorer.get_scores(row['answer_llm'], row['answer_orig'])[0]\n",
    "    return {\n",
    "        'rouge_1': scores['rouge-1']['f'],\n",
    "        'rouge_2': scores['rouge-2']['f'],\n",
    "        'rouge_l': scores['rouge-l']['f']\n",
    "    }\n",
    "\n",
    "# Compute ROUGE scores for all rows\n",
    "rouge_scores = df.apply(compute_rouge_scores, axis=1)\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "rouge_df = pd.DataFrame(rouge_scores.tolist())\n",
    "\n",
    "# Calculate the average ROUGE-2 score\n",
    "average_rouge_2 = rouge_df['rouge_2'].mean()\n",
    "\n",
    "print(f\"The average ROUGE-2 score across all records is: {average_rouge_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
